"use strict";(self.webpackChunkbento=self.webpackChunkbento||[]).push([[2806],{63375:function(e,r,n){n.r(r),n.d(r,{assets:function(){return d},contentTitle:function(){return l},default:function(){return p},frontMatter:function(){return i},metadata:function(){return c},toc:function(){return u}});var t=n(85893),s=n(11151),a=n(74866),o=n(85162);const i={title:"retry",slug:"retry",type:"processor",status:"beta",categories:["Composition"],name:"retry"},l=void 0,c={id:"components/processors/retry",title:"retry",description:"\x3c!--",source:"@site/docs/components/processors/retry.md",sourceDirName:"components/processors",slug:"/components/processors/retry",permalink:"/bento/docs/components/processors/retry",draft:!1,unlisted:!1,editUrl:"https://github.com/warpstreamlabs/bento/edit/main/website/docs/components/processors/retry.md",tags:[],version:"current",frontMatter:{title:"retry",slug:"retry",type:"processor",status:"beta",categories:["Composition"],name:"retry"},sidebar:"docs",previous:{title:"resource",permalink:"/bento/docs/components/processors/resource"},next:{title:"schema_registry_decode",permalink:"/bento/docs/components/processors/schema_registry_decode"}},d={},u=[{value:"Examples",id:"examples",level:2},{value:"Fields",id:"fields",level:2},{value:"<code>backoff</code>",id:"backoff",level:3},{value:"<code>backoff.initial_interval</code>",id:"backoffinitial_interval",level:3},{value:"<code>backoff.max_interval</code>",id:"backoffmax_interval",level:3},{value:"<code>backoff.max_elapsed_time</code>",id:"backoffmax_elapsed_time",level:3},{value:"<code>processors</code>",id:"processors",level:3},{value:"<code>parallel</code>",id:"parallel",level:3},{value:"Batching",id:"batching",level:2}];function h(e){const r={a:"a",admonition:"admonition",br:"br",code:"code",em:"em",h2:"h2",h3:"h3",p:"p",pre:"pre",...(0,s.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(r.admonition,{title:"BETA",type:"caution",children:(0,t.jsx)(r.p,{children:"This component is mostly stable but breaking changes could still be made outside of major version releases if a fundamental problem with the component is found."})}),"\n",(0,t.jsx)(r.p,{children:"Attempts to execute a series of child processors until success."}),"\n",(0,t.jsx)(r.p,{children:"Introduced in version 4.27.0."}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-yml",children:'# Config fields, showing default values\nlabel: ""\nretry:\n  backoff:\n    initial_interval: 500ms\n    max_interval: 10s\n    max_elapsed_time: 1m\n  processors: [] # No default (required)\n  parallel: false\n'})}),"\n",(0,t.jsxs)(r.p,{children:["Executes child processors and if a resulting message is errored then, after a specified backoff period, the same original message will be attempted again through those same processors. If the child processors result in more than one message then the retry mechanism will kick in if ",(0,t.jsx)(r.em,{children:"any"})," of the resulting messages are errored."]}),"\n",(0,t.jsx)(r.p,{children:"It is important to note that any mutations performed on the message during these child processors will be discarded for the next retry, and therefore it is safe to assume that each execution of the child processors will always be performed on the data as it was when it first reached the retry processor."}),"\n",(0,t.jsxs)(r.p,{children:["By default the retry backoff has a specified ",(0,t.jsx)(r.a,{href:"#backoffmax_elapsed_time",children:(0,t.jsx)(r.code,{children:"max_elapsed_time"})}),", if this time period is reached during retries and an error still occurs these errored messages will proceed through to the next processor after the retry (or your outputs). Normal ",(0,t.jsx)(r.a,{href:"/docs/configuration/error_handling",children:"error handling patterns"})," can be used on these messages."]}),"\n",(0,t.jsx)(r.p,{children:"In order to avoid permanent loops any error associated with messages as they first enter a retry processor will be cleared."}),"\n",(0,t.jsx)(r.admonition,{title:"Batching",type:"caution",children:(0,t.jsxs)(r.p,{children:["If you wish to wrap a batch-aware series of processors then take a look at the ",(0,t.jsx)(r.a,{href:"#batching",children:"batching section"})," below."]})}),"\n",(0,t.jsx)(r.h2,{id:"examples",children:"Examples"}),"\n",(0,t.jsx)(a.Z,{defaultValue:"Stop ignoring me Taz",values:[{label:"Stop ignoring me Taz",value:"Stop ignoring me Taz"}],children:(0,t.jsxs)(o.Z,{value:"Stop ignoring me Taz",children:[(0,t.jsx)(r.p,{children:"Here we have a config where I generate animal noises and send them to Taz via HTTP. Taz has a tendency to stop his servers whenever I dispatch my animals upon him, and therefore these HTTP requests sometimes fail. However, I have the retry processor and with this super power I can specify a back off policy and it will ensure that for each animal noise the HTTP processor is attempted until either it succeeds or my Bento instance is stopped."}),(0,t.jsx)(r.p,{children:"I even go as far as to zero-out the maximum elapsed time field, which means that for each animal noise I will wait indefinitely, because I really really want Taz to receive every single animal noise that he is entitled to."}),(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-yaml",children:'input:\n  generate:\n    interval: 1s\n    mapping: \'root.noise = [ "woof", "meow", "moo", "quack" ].index(random_int(min: 0, max: 3))\'\n\npipeline:\n  processors:\n    - retry:\n        backoff:\n          initial_interval: 100ms\n          max_interval: 5s\n          max_elapsed_time: 0s\n        processors:\n          - http:\n              url: \'http://example.com/try/not/to/dox/taz\'\n              verb: POST\n\noutput:\n  # Drop everything because it\'s junk data, I don\'t want it lol\n  drop: {}\n'})})]})}),"\n",(0,t.jsx)(r.h2,{id:"fields",children:"Fields"}),"\n",(0,t.jsx)(r.h3,{id:"backoff",children:(0,t.jsx)(r.code,{children:"backoff"})}),"\n",(0,t.jsx)(r.p,{children:"Determine time intervals and cut offs for retry attempts."}),"\n",(0,t.jsxs)(r.p,{children:["Type: ",(0,t.jsx)(r.code,{children:"object"})]}),"\n",(0,t.jsx)(r.h3,{id:"backoffinitial_interval",children:(0,t.jsx)(r.code,{children:"backoff.initial_interval"})}),"\n",(0,t.jsx)(r.p,{children:"The initial period to wait between retry attempts."}),"\n",(0,t.jsxs)(r.p,{children:["Type: ",(0,t.jsx)(r.code,{children:"string"}),(0,t.jsx)(r.br,{}),"\n","Default: ",(0,t.jsx)(r.code,{children:'"500ms"'})]}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-yml",children:"# Examples\n\ninitial_interval: 50ms\n\ninitial_interval: 1s\n"})}),"\n",(0,t.jsx)(r.h3,{id:"backoffmax_interval",children:(0,t.jsx)(r.code,{children:"backoff.max_interval"})}),"\n",(0,t.jsx)(r.p,{children:"The maximum period to wait between retry attempts"}),"\n",(0,t.jsxs)(r.p,{children:["Type: ",(0,t.jsx)(r.code,{children:"string"}),(0,t.jsx)(r.br,{}),"\n","Default: ",(0,t.jsx)(r.code,{children:'"10s"'})]}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-yml",children:"# Examples\n\nmax_interval: 5s\n\nmax_interval: 1m\n"})}),"\n",(0,t.jsx)(r.h3,{id:"backoffmax_elapsed_time",children:(0,t.jsx)(r.code,{children:"backoff.max_elapsed_time"})}),"\n",(0,t.jsxs)(r.p,{children:["The maximum overall period of time to spend on retry attempts before the request is aborted. Setting this value to a zeroed duration (such as ",(0,t.jsx)(r.code,{children:"0s"}),") will result in unbounded retries."]}),"\n",(0,t.jsxs)(r.p,{children:["Type: ",(0,t.jsx)(r.code,{children:"string"}),(0,t.jsx)(r.br,{}),"\n","Default: ",(0,t.jsx)(r.code,{children:'"1m"'})]}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-yml",children:"# Examples\n\nmax_elapsed_time: 1m\n\nmax_elapsed_time: 1h\n"})}),"\n",(0,t.jsx)(r.h3,{id:"processors",children:(0,t.jsx)(r.code,{children:"processors"})}),"\n",(0,t.jsxs)(r.p,{children:["A list of ",(0,t.jsx)(r.a,{href:"/docs/components/processors/about/",children:"processors"})," to execute on each message."]}),"\n",(0,t.jsxs)(r.p,{children:["Type: ",(0,t.jsx)(r.code,{children:"array"})]}),"\n",(0,t.jsx)(r.h3,{id:"parallel",children:(0,t.jsx)(r.code,{children:"parallel"})}),"\n",(0,t.jsxs)(r.p,{children:["When processing batches of messages these batches are ignored and the processors apply to each message sequentially. However, when this field is set to ",(0,t.jsx)(r.code,{children:"true"})," each message will be processed in parallel. Caution should be made to ensure that batch sizes do not surpass a point where this would cause resource (CPU, memory, API limits) contention."]}),"\n",(0,t.jsxs)(r.p,{children:["Type: ",(0,t.jsx)(r.code,{children:"bool"}),(0,t.jsx)(r.br,{}),"\n","Default: ",(0,t.jsx)(r.code,{children:"false"})]}),"\n",(0,t.jsx)(r.h2,{id:"batching",children:"Batching"}),"\n",(0,t.jsxs)(r.p,{children:["When messages are batched the child processors of a retry are executed for each individual message in isolation, performed serially by default but in parallel when the field ",(0,t.jsx)(r.a,{href:"#parallel",children:(0,t.jsx)(r.code,{children:"parallel"})})," is set to ",(0,t.jsx)(r.code,{children:"true"}),". This is an intentional limitation of the retry processor and is done in order to ensure that errors are correctly associated with a given input message. Otherwise, the archiving, expansion, grouping, filtering and so on of the child processors could obfuscate this relationship."]}),"\n",(0,t.jsxs)(r.p,{children:['If the target behaviour of your retried processors is "batch aware", in that you wish to perform some processing across the entire batch of messages and repeat it in the event of errors, you can use an ',(0,t.jsxs)(r.a,{href:"/docs/components/processors/archive",children:[(0,t.jsx)(r.code,{children:"archive"})," processor"]})," to collapse the batch into an individual message. Then, within these child processors either perform your batch aware processing on the archive, or use an ",(0,t.jsxs)(r.a,{href:"/docs/components/processors/unarchive",children:[(0,t.jsx)(r.code,{children:"unarchive"})," processor"]})," in order to expand the single message back out into a batch."]}),"\n",(0,t.jsx)(r.p,{children:"For example, if the retry processor were being used to wrap an HTTP request where the payload data is a batch archived into a JSON array it should look something like this:"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-yaml",children:"pipeline:\n  processors:\n    - archive:\n        format: json_array\n    - retry:\n        processors:\n          - http:\n              url: example.com/nope\n              verb: POST\n    - unarchive:\n        format: json_array\n"})})]})}function p(e={}){const{wrapper:r}={...(0,s.a)(),...e.components};return r?(0,t.jsx)(r,{...e,children:(0,t.jsx)(h,{...e})}):h(e)}},85162:function(e,r,n){n.d(r,{Z:function(){return o}});n(67294);var t=n(86010),s={tabItem:"tabItem_Ymn6"},a=n(85893);function o(e){let{children:r,hidden:n,className:o}=e;return(0,a.jsx)("div",{role:"tabpanel",className:(0,t.Z)(s.tabItem,o),hidden:n,children:r})}},74866:function(e,r,n){n.d(r,{Z:function(){return w}});var t=n(67294),s=n(86010),a=n(12466),o=n(16550),i=n(20469),l=n(91980),c=n(67392),d=n(50012);function u(e){var r,n;return null!=(r=null==(n=t.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,t.isValidElement)(e)&&function(e){const{props:r}=e;return!!r&&"object"==typeof r&&"value"in r}(e))return e;throw new Error("Docusaurus error: Bad <Tabs> child <"+("string"==typeof e.type?e.type:e.type.name)+'>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.')})))?void 0:n.filter(Boolean))?r:[]}function h(e){const{values:r,children:n}=e;return(0,t.useMemo)((()=>{const e=null!=r?r:function(e){return u(e).map((e=>{let{props:{value:r,label:n,attributes:t,default:s}}=e;return{value:r,label:n,attributes:t,default:s}}))}(n);return function(e){const r=(0,c.l)(e,((e,r)=>e.value===r.value));if(r.length>0)throw new Error('Docusaurus error: Duplicate values "'+r.map((e=>e.value)).join(", ")+'" found in <Tabs>. Every value needs to be unique.')}(e),e}),[r,n])}function p(e){let{value:r,tabValues:n}=e;return n.some((e=>e.value===r))}function m(e){let{queryString:r=!1,groupId:n}=e;const s=(0,o.k6)(),a=function(e){let{queryString:r=!1,groupId:n}=e;if("string"==typeof r)return r;if(!1===r)return null;if(!0===r&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return null!=n?n:null}({queryString:r,groupId:n});return[(0,l._X)(a),(0,t.useCallback)((e=>{if(!a)return;const r=new URLSearchParams(s.location.search);r.set(a,e),s.replace({...s.location,search:r.toString()})}),[a,s])]}function f(e){const{defaultValue:r,queryString:n=!1,groupId:s}=e,a=h(e),[o,l]=(0,t.useState)((()=>function(e){var r;let{defaultValue:n,tabValues:t}=e;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!p({value:n,tabValues:t}))throw new Error('Docusaurus error: The <Tabs> has a defaultValue "'+n+'" but none of its children has the corresponding value. Available values are: '+t.map((e=>e.value)).join(", ")+". If you intend to show no default tab, use defaultValue={null} instead.");return n}const s=null!=(r=t.find((e=>e.default)))?r:t[0];if(!s)throw new Error("Unexpected error: 0 tabValues");return s.value}({defaultValue:r,tabValues:a}))),[c,u]=m({queryString:n,groupId:s}),[f,b]=function(e){let{groupId:r}=e;const n=function(e){return e?"docusaurus.tab."+e:null}(r),[s,a]=(0,d.Nk)(n);return[s,(0,t.useCallback)((e=>{n&&a.set(e)}),[n,a])]}({groupId:s}),x=(()=>{const e=null!=c?c:f;return p({value:e,tabValues:a})?e:null})();(0,i.Z)((()=>{x&&l(x)}),[x]);return{selectedValue:o,selectValue:(0,t.useCallback)((e=>{if(!p({value:e,tabValues:a}))throw new Error("Can't select invalid tab value="+e);l(e),u(e),b(e)}),[u,b,a]),tabValues:a}}var b=n(72389),x={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"},v=n(85893);function g(e){let{className:r,block:n,selectedValue:t,selectValue:o,tabValues:i}=e;const l=[],{blockElementScrollPositionUntilNextRender:c}=(0,a.o5)(),d=e=>{const r=e.currentTarget,n=l.indexOf(r),s=i[n].value;s!==t&&(c(r),o(s))},u=e=>{var r;let n=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{var t;const r=l.indexOf(e.currentTarget)+1;n=null!=(t=l[r])?t:l[0];break}case"ArrowLeft":{var s;const r=l.indexOf(e.currentTarget)-1;n=null!=(s=l[r])?s:l[l.length-1];break}}null==(r=n)||r.focus()};return(0,v.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,s.Z)("tabs",{"tabs--block":n},r),children:i.map((e=>{let{value:r,label:n,attributes:a}=e;return(0,v.jsx)("li",{role:"tab",tabIndex:t===r?0:-1,"aria-selected":t===r,ref:e=>l.push(e),onKeyDown:u,onClick:d,...a,className:(0,s.Z)("tabs__item",x.tabItem,null==a?void 0:a.className,{"tabs__item--active":t===r}),children:null!=n?n:r},r)}))})}function y(e){let{lazy:r,children:n,selectedValue:s}=e;const a=(Array.isArray(n)?n:[n]).filter(Boolean);if(r){const e=a.find((e=>e.props.value===s));return e?(0,t.cloneElement)(e,{className:"margin-top--md"}):null}return(0,v.jsx)("div",{className:"margin-top--md",children:a.map(((e,r)=>(0,t.cloneElement)(e,{key:r,hidden:e.props.value!==s})))})}function j(e){const r=f(e);return(0,v.jsxs)("div",{className:(0,s.Z)("tabs-container",x.tabList),children:[(0,v.jsx)(g,{...e,...r}),(0,v.jsx)(y,{...e,...r})]})}function w(e){const r=(0,b.Z)();return(0,v.jsx)(j,{...e,children:u(e.children)},String(r))}},11151:function(e,r,n){n.d(r,{Z:function(){return i},a:function(){return o}});var t=n(67294);const s={},a=t.createContext(s);function o(e){const r=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(r):{...r,...e}}),[r,e])}function i(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),t.createElement(a.Provider,{value:r},e.children)}}}]);